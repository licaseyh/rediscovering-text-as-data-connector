{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "from datascience import *\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "import gensim\n",
    "import nltk\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding\n",
    "\n",
    "This lesson is designed to explore features of word embeddings described by Ben Schmidt in his blog post <a href=\"http://bookworm.benschmidt.org/posts/2015-10-30-rejecting-the-gender-binary.html\">\"Rejecting the Gender Binary\"</a>.\n",
    "\n",
    "The primary corpus we use consists of the <a href=\"http://txtlab.org/?p=601\">150 English-language novels</a> made available by the .txtLab at McGill. We also look at a <a href=\"http://ryanheuser.org/word-vectors-1/\">Word2Vec model trained on the ECCO-TCP corpus</a> of 2,350 eighteenth-century literary texts made available by Ryan Heuser. (I have shortened the number of terms in the model by half in order to conserve memory.)\n",
    "\n",
    "For background on Word2Vec's mechanics, I suggest this <a href=\"https://www.tensorflow.org/versions/r0.8/tutorials/word2vec/index.html\">brief tutorial</a> by Google, especially the sections \"Motivation,\" \"Skip-Gram Model,\" and \"Visualizing.\"\n",
    "\n",
    "We'll read in Andrew Piper's corpus we used in our Topic Modeling notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_tb = Table.read_table('../09-Topic-Modeling/data/txtlab_Novel150_English.csv')\n",
    "\n",
    "fiction_path = '../09-Topic-Modeling/data/txtlab_Novel150_English/'\n",
    "\n",
    "novel_list = []\n",
    "\n",
    "# Iterate through filenames in metadata table\n",
    "for filename in metadata_tb['filename']:\n",
    "    \n",
    "    # Read in novel text as single string, make lowercase\n",
    "    with open(fiction_path + filename, 'r') as file_in:\n",
    "        novel = file_in.read()\n",
    "    \n",
    "    # Add novel text as single string to master list\n",
    "    novel_list.append(novel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Pre-Processing\n",
    "\n",
    "Word2Vec learns about the relationships among words by observing them in context. We'll need to tokenize the words in our corpus while retaining sentence boundaries. Since novels were imported as single strings, we'll first use <i>sent_tokenize</i> to divide them into sentences, and second, we'll split each sentence into its own list of words.\n",
    "\n",
    "We'll use `nltk`'s sentence tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to memory and time constraints we'll use our quick and dirty tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_tokenize(text):\n",
    "    \n",
    "    # Iterate through text removing punctuation characters\n",
    "    no_punct = \"\".join([char for char in text if char not in punctuation])\n",
    "    \n",
    "    # Split text over whitespace into list of words\n",
    "    tokens = no_punct.split()\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First get the sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [sentence for novel in novel_list for sentence in sent_tokenize(novel)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_by_sentence = [fast_tokenize(sentence.lower()) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll double check that we don't have any empty sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_by_sentence = [sentence for sentence in words_by_sentence if sentence != []]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now have a `list` of `list`s with sentences and words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['author’s',\n",
       "  'introduction',\n",
       "  'my',\n",
       "  'dog',\n",
       "  'had',\n",
       "  'made',\n",
       "  'a',\n",
       "  'point',\n",
       "  'on',\n",
       "  'a',\n",
       "  'piece',\n",
       "  'of',\n",
       "  'fallowground',\n",
       "  'and',\n",
       "  'led',\n",
       "  'the',\n",
       "  'curate',\n",
       "  'and',\n",
       "  'me',\n",
       "  'two',\n",
       "  'or',\n",
       "  'three',\n",
       "  'hundred',\n",
       "  'yards',\n",
       "  'over',\n",
       "  'that',\n",
       "  'and',\n",
       "  'some',\n",
       "  'stubble',\n",
       "  'adjoining',\n",
       "  'in',\n",
       "  'a',\n",
       "  'breathless',\n",
       "  'state',\n",
       "  'of',\n",
       "  'expectation',\n",
       "  'on',\n",
       "  'a',\n",
       "  'burning',\n",
       "  'first',\n",
       "  'of',\n",
       "  'september'],\n",
       " ['it',\n",
       "  'was',\n",
       "  'a',\n",
       "  'false',\n",
       "  'point',\n",
       "  'and',\n",
       "  'our',\n",
       "  'labour',\n",
       "  'was',\n",
       "  'vain',\n",
       "  'yet',\n",
       "  'to',\n",
       "  'do',\n",
       "  'rover',\n",
       "  'justice',\n",
       "  'for',\n",
       "  'he’s',\n",
       "  'an',\n",
       "  'excellent',\n",
       "  'dog',\n",
       "  'though',\n",
       "  'i',\n",
       "  'have',\n",
       "  'lost',\n",
       "  'his',\n",
       "  'pedigree',\n",
       "  'the',\n",
       "  'fault',\n",
       "  'was',\n",
       "  'none',\n",
       "  'of',\n",
       "  'his',\n",
       "  'the',\n",
       "  'birds',\n",
       "  'were',\n",
       "  'gone',\n",
       "  'the',\n",
       "  'curate',\n",
       "  'showed',\n",
       "  'me',\n",
       "  'the',\n",
       "  'spot',\n",
       "  'where',\n",
       "  'they',\n",
       "  'had',\n",
       "  'lain',\n",
       "  'basking',\n",
       "  'at',\n",
       "  'the',\n",
       "  'root',\n",
       "  'of',\n",
       "  'an',\n",
       "  'old',\n",
       "  'hedge']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_by_sentence[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "# Word2Vec\n",
    "\n",
    "### Word Embeddings\n",
    "Word2Vec is the most prominent word embedding algorithm. Word embedding generally attempts to identify semantic relationships between words by observing them in context.\n",
    "\n",
    "Imagine that each word in a novel has its meaning determined by the ones that surround it in a limited window. For example, in Moby Dick's first sentence, “me” is paired on either side by “Call” and “Ishmael.” After observing the windows around every word in the novel (or many novels), the computer will notice a pattern in which “me” falls between similar pairs of words to “her,” “him,” or “them.” Of course, the computer had gone through a similar process over the words “Call” and “Ishmael,” for which “me” is reciprocally part of their contexts.  This chaining of signifiers to one another mirrors some of humanists' most sophisticated interpretative frameworks of language.\n",
    "\n",
    "The two main flavors of Word2Vec are CBOW (Continuous Bag of Words) and Skip-Gram, which can be distinguished partly by their input and output during training. Skip-Gram takes a word of interest as its input (e.g. \"me\") and tries to learn how to predict its context words (\"Call\",\"Ishmael\"). CBOW does the opposite, taking the context words (\"Call\",\"Ishmael\") as a single input and tries to predict the word of interest (\"me\").\n",
    "\n",
    "In general, CBOW is is faster and does well with frequent words, while Skip-Gram potentially represents rare words better.\n",
    "\n",
    "### Word2Vec Features\n",
    "<ul>\n",
    "<li>`size`: Number of dimensions for word embedding model</li>\n",
    "<li>`window`: Number of context words to observe in each direction</li>\n",
    "<li>`min_count`: Minimum frequency for words included in model</li>\n",
    "<li>`sg` (Skip-Gram): '0' indicates CBOW model; '1' indicates Skip-Gram</li>\n",
    "<li>`alpha`: Learning rate (initial); prevents model from over-correcting, enables finer tuning</li>\n",
    "<li>`iterations`: Number of passes through dataset</li>\n",
    "<li>`batch_words`: Number of words to sample from data during each pass</li>\n",
    "</ul>\n",
    "\n",
    "Note: cell below uses default value for each argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We've gotten accustomed to training powerful models in Python with one line of code, why stop now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(words_by_sentence, size=100, window=5, \\\n",
    "                               min_count=5, sg=0, alpha=0.025, iter=5, batch_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "We can return the actual high-dimensional vector by simply indexing the model with the word as the key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.06160772,  0.21247992,  1.12522173,  0.53051025, -0.53191495,\n",
       "        1.0799768 , -1.22531927,  0.40825477, -0.06397039,  2.51139307,\n",
       "       -0.34302995,  1.15381885,  2.56682253, -0.70385349,  1.26121151,\n",
       "        0.15218158,  0.91631103,  1.15056682,  0.4848581 , -2.19859123,\n",
       "        0.17676759,  0.82537079, -1.16751111,  1.04999685,  1.22517633,\n",
       "        1.44359875, -0.87301463,  0.61490577, -0.17735787, -0.51032293,\n",
       "       -1.18286633,  2.36878371, -0.71106267, -0.71233767,  1.79720354,\n",
       "       -0.24261512,  0.44561961,  2.21126103, -0.3768543 , -1.44865775,\n",
       "        0.77676547, -1.09276688, -0.72423452, -0.53959996,  2.1961391 ,\n",
       "        0.29632694, -0.3504656 , -1.27681494, -1.80313957, -0.66970581,\n",
       "        2.43341327,  0.20558025, -2.44037938,  1.57155204,  0.06480936,\n",
       "        0.78582162,  1.37335408, -0.71212876, -0.96540165, -0.91900319,\n",
       "       -0.42244014, -2.32061481, -1.02056313, -0.49769622,  1.67989123,\n",
       "       -0.07009229,  2.11574936,  0.75349408, -0.36731079,  0.3468557 ,\n",
       "       -0.00406742,  1.40303814,  0.86173385, -1.3560344 , -2.09102511,\n",
       "       -0.80814016,  0.13324794, -0.50825024, -0.57124752, -0.82800776,\n",
       "        0.65092039,  0.64725661, -1.49583995,  0.19819875, -0.87745881,\n",
       "       -0.84169066, -0.3173641 , -0.26012653, -0.16477011,  0.50417787,\n",
       "       -0.8529281 ,  2.15986633,  0.96799326,  0.33212179, -0.50202042,\n",
       "       -0.19490387,  0.31198362,  0.65629297, -0.21388899, -1.24712837], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['whale']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gensim` comes with some handy methods to analyze word relationships. `similarity` will give us a number from 0-1 based on how similar two words are. If this sounds like cosine similarity for words, you'd be right! It just takes the cosine similarity of these high dimensional vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67752171846260123"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('sense','sensibility')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also find cosine distance between two clusters of word vectors. Each cluster is measured as the mean of its words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.137912410241886"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_similarity(['sense','sensibility'],['whale','harpoon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find words that don't belong with `doesnt_match`. It finds the mean vector of the words in the `list`, and identifies the furthest away:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'harpoon'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(['pride','prejudice', 'harpoon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most famous implementation of this vector math is semantics. What happens if we take:\n",
    "\n",
    "$$King - Man + Woman = $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('princess', 0.7382299900054932),\n",
       " ('queen', 0.7070746421813965),\n",
       " ('duke', 0.6797616481781006),\n",
       " ('duchess', 0.6795263290405273),\n",
       " ('chevalier', 0.6742004156112671),\n",
       " ('saint', 0.6714754104614258),\n",
       " ('priest', 0.6646419763565063),\n",
       " ('emperor', 0.6621493101119995),\n",
       " ('earl', 0.6521003842353821),\n",
       " ('solomon', 0.6499632596969604)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schmidt looked at words associated with male and female pronouns to investigate gender. Let's try take all the female pronouns and subtracting the male pronouns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lovely', 0.5201287269592285),\n",
       " ('sweet', 0.49211084842681885),\n",
       " ('beautiful', 0.4811100661754608),\n",
       " ('miss', 0.4612177014350891),\n",
       " ('maiden', 0.4426001310348511),\n",
       " ('beauty', 0.4329194128513336),\n",
       " ('soft', 0.42993593215942383),\n",
       " ('girlish', 0.42027080059051514),\n",
       " ('charming', 0.419153094291687),\n",
       " ('anne', 0.41564005613327026)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['she','her','hers','herself'], negative=['he','him','his','himself'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the opposite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('moby', 0.4661307632923126),\n",
       " ('horse', 0.4568333625793457),\n",
       " ('manfully', 0.42629876732826233),\n",
       " ('buck', 0.42477506399154663),\n",
       " ('realestate', 0.42052629590034485),\n",
       " ('bill', 0.41748833656311035),\n",
       " ('cherokee', 0.41504210233688354),\n",
       " ('king', 0.4090022146701813),\n",
       " ('captain', 0.408931702375412),\n",
       " ('constable', 0.40539032220840454)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['he','him','his','himself'], negative=['she','her','hers','herself'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about together (*genderless* in Schmidt's sense)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('eugenia', 0.6196630001068115),\n",
       " ('camilla', 0.5995502471923828),\n",
       " ('edgar', 0.5902959108352661),\n",
       " ('indiana', 0.5881960391998291),\n",
       " ('algernon', 0.586357593536377),\n",
       " ('itself', 0.585890531539917),\n",
       " ('them', 0.5818917751312256),\n",
       " ('carrie', 0.5692876577377319),\n",
       " ('it', 0.5648031830787659),\n",
       " ('margaret', 0.5620149374008179),\n",
       " ('eleanor', 0.5559800863265991),\n",
       " ('erica', 0.5459800958633423),\n",
       " ('rebecca', 0.5457961559295654),\n",
       " ('adeline', 0.5426214337348938),\n",
       " ('constraint', 0.5411407947540283),\n",
       " ('heyward', 0.5403339266777039),\n",
       " ('rhoda', 0.5347437262535095),\n",
       " ('cora', 0.5206751823425293),\n",
       " ('munro', 0.5170658826828003),\n",
       " ('amy', 0.5155044198036194),\n",
       " ('leonora', 0.5146893262863159),\n",
       " ('antonia', 0.5144892930984497),\n",
       " ('lily', 0.5092915892601013),\n",
       " ('catherine', 0.5059593915939331),\n",
       " ('edward', 0.5051007270812988),\n",
       " ('valancourt', 0.5031650066375732),\n",
       " ('me', 0.5030218362808228),\n",
       " ('emily', 0.5019703507423401),\n",
       " ('resistance', 0.5019262433052063),\n",
       " ('maggie', 0.501758337020874),\n",
       " ('jo', 0.5010125637054443),\n",
       " ('magua', 0.4993283152580261),\n",
       " ('elinor', 0.4982890188694),\n",
       " ('duncan', 0.49426591396331787),\n",
       " ('gloria', 0.49211201071739197),\n",
       " ('kim', 0.49155908823013306),\n",
       " ('isabel', 0.49155521392822266),\n",
       " ('monica', 0.49096399545669556),\n",
       " ('cecilia', 0.49065789580345154),\n",
       " ('savonarola', 0.48905715346336365),\n",
       " ('hurstwood', 0.4858826696872711),\n",
       " ('anthony', 0.48512282967567444),\n",
       " ('myself', 0.48421505093574524),\n",
       " ('marianne', 0.4831082224845886),\n",
       " ('baldassarre', 0.4797833561897278),\n",
       " ('latter', 0.4796856939792633),\n",
       " ('cowperwood', 0.4777473211288452),\n",
       " ('aileen', 0.4777010381221771),\n",
       " ('anxiety', 0.47599396109580994),\n",
       " ('agatha', 0.47598540782928467)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['she','her','hers','herself','he','him','his','himself'], topn=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Homework\n",
    "\n",
    "Use the `most_similar` method to find the tokens nearest to 'car' in our model. Do the same for 'motorcar'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('coach', 0.8499592542648315),\n",
       " ('cart', 0.8190828561782837),\n",
       " ('cab', 0.8166661858558655),\n",
       " ('wagon', 0.8020604848861694),\n",
       " ('sled', 0.7872979044914246),\n",
       " ('vehicle', 0.7860080003738403),\n",
       " ('steamer', 0.7850623726844788),\n",
       " ('chaise', 0.7819366455078125),\n",
       " ('buggy', 0.7794481515884399),\n",
       " ('carriage', 0.7757760882377625)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['car'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('secondclass', 0.7423557043075562),\n",
       " ('offals', 0.7399462461471558),\n",
       " ('grassplat', 0.7359715700149536),\n",
       " ('brodersons', 0.7293741703033447),\n",
       " ('coalscuttle', 0.7288597226142883),\n",
       " ('façade', 0.7213620543479919),\n",
       " ('sligo', 0.7192723751068115),\n",
       " ('greenhouses', 0.7182039022445679),\n",
       " ('skaguay', 0.7100757956504822),\n",
       " ('latrine', 0.7098667621612549)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['motorcar'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What characterizes each word in our corpus? Does this make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each word is characterized by its relationship to the words around it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Vector addition and subtraction can be thought of in terms of analogy. From the example above: 'man' is to 'king' as 'woman' is to '???'. Use the `most_similar` method to find: 'paris' is to 'france' as 'london' is to '???'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('england', 0.8406458497047424),\n",
       " ('spain', 0.7943618297576904),\n",
       " ('italy', 0.7885047197341919),\n",
       " ('germany', 0.7721696496009827),\n",
       " ('ireland', 0.7684625387191772),\n",
       " ('america', 0.7622525691986084),\n",
       " ('europe', 0.7435410022735596),\n",
       " ('scotland', 0.722425103187561),\n",
       " ('philadelphia', 0.7118967771530151),\n",
       " ('india', 0.7042458057403564)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['london', 'france'], negative=['paris'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What has our model learned about nation-states?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model has learned that nation-states have some distinct place-names of special importance, which are what we think of capitol cities. There is a one-to-one relationship between nation-states and capitol cities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Perform the canonic Word2Vec addition again but leave out a term. Try 'king' - 'man', 'woman' - 'man', 'woman' + 'king'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kings', 0.4990139305591583),\n",
       " ('ravenshaw', 0.49890071153640747),\n",
       " ('stornaway', 0.49746328592300415),\n",
       " ('ruritania', 0.4890238642692566),\n",
       " ('casimir', 0.48799920082092285),\n",
       " ('steyne', 0.4879959225654602),\n",
       " ('hunter’s', 0.480550080537796),\n",
       " ('royal', 0.4792546331882477),\n",
       " ('tarlenheim', 0.4790828824043274),\n",
       " ('macadams', 0.47874486446380615)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('louisa', 0.5380529165267944),\n",
       " ('bloofer', 0.5338019728660583),\n",
       " ('maiden', 0.5212978720664978),\n",
       " ('jane', 0.49439841508865356),\n",
       " ('maid', 0.4906766414642334),\n",
       " ('lovely', 0.48193681240081787),\n",
       " ('beautiful', 0.4750133156776428),\n",
       " ('glencora', 0.46966272592544556),\n",
       " ('baldock', 0.46382027864456177),\n",
       " ('charming', 0.46105340123176575)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['woman'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('priest', 0.8030697703361511),\n",
       " ('jew', 0.7955906391143799),\n",
       " ('man', 0.7843015193939209),\n",
       " ('poet', 0.7667089700698853),\n",
       " ('nobleman', 0.7607263922691345),\n",
       " ('clergyman', 0.7549895644187927),\n",
       " ('frenchman', 0.749399721622467),\n",
       " ('jewess', 0.7484939694404602),\n",
       " ('minister', 0.7427135705947876),\n",
       " ('citizen', 0.7424870133399963)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['woman', 'king'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What do these indicate semantically?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These indicate semantically that a 'king' that is not a 'man' might be a 'sheba,' a 'woman' without the semantic meaning of 'man' is likely a 'beautiful' 'maiden' named 'jane,' and that a 'woman' who is also a 'king' might be a 'priest.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Visualization\n",
    "\n",
    "We can use multi-dimensional scaling to visualize this space just like we did with the documents before. But there are a lot of words here, so let's limit it to 50 words from our female gendered subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "her_tokens = [token for token,weight in model.most_similar(positive=['she','her','hers','herself'], \\\n",
    "                                                       negative=['he','him','his','himself'], topn=50)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to get the vector from each word, just like above, and add that to a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = [model[word] for word in her_tokens]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then calculate pairwise the cosine distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise\n",
    "dist_matrix = pairwise.pairwise_distances(vectors, metric='cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use `MDS` to reduce the dimensions to two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "mds = MDS(n_components = 2, dissimilarity='precomputed')\n",
    "embeddings = mds.fit_transform(dist_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some fancy `matplotlib` code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAJCCAYAAAD+96JYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFwAAgIUoXwAAABaifAEAAFjo/wC+zEbleHmwVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb6f0ac12e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, ax = plt.subplots(figsize=(10,10))\n",
    "ax.scatter(embeddings[:,0], embeddings[:,1], alpha=0)\n",
    "for i in range(len(vectors)):\n",
    "    ax.annotate(her_tokens[i], ((embeddings[i,0], embeddings[i,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What kinds of semantic relationships exist in the diagram above? Are there any words that seem out of place? How do you think they go there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting to observe semantic relationships even among the words that are coded as feminine. How are 'mothers' different from 'delicate,' 'girlish' 'beauty?\"\n",
    "\n",
    "I think it is so funny that 'Doris' is a real outlier. If you are named 'Doris' you don't seem to be 'innocent', 'maternal,' 'radiant,' 'delicate,' or 'peerless,' but you are semantically similar to 'harden.' Congratulations, Doris. Why is 'harden' in this diagram anyways?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Saving/Loading Models\n",
    "\n",
    "We can save the model as a `.txt` file with the `save_word2vec_format` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('word2vec.txtalb_Novel150_English.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load up a model, we just ask `gensim`. Here's a model trained on Eighteenth Century Collections Online corpus (~2500 texts) made available by Ryan Heuser: http://ryanheuser.org/word-vectors-1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecco_model = gensim.models.KeyedVectors.load_word2vec_format('data/word2vec.ECCO-TCP.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7854657173156738),\n",
       " ('emperor', 0.7523162364959717),\n",
       " ('prince', 0.7436755895614624),\n",
       " ('princess', 0.713316798210144),\n",
       " ('conqueror', 0.7111818194389343),\n",
       " ('regent', 0.7088087797164917),\n",
       " ('empress', 0.6977599263191223),\n",
       " ('sultan', 0.6729022264480591),\n",
       " ('confessor', 0.6569845676422119),\n",
       " ('duke', 0.6366889476776123)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecco_model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"harriet's\", 0.5708541870117188),\n",
       " ('softness', 0.5513930320739746),\n",
       " ('maiden', 0.5411286354064941),\n",
       " (\"chloe's\", 0.5403314828872681),\n",
       " ('lovely', 0.5320479869842529),\n",
       " ('coy', 0.5259038209915161),\n",
       " ('bewitching', 0.5255858898162842),\n",
       " ('soft', 0.5217857956886292),\n",
       " ('blushing', 0.5112706422805786),\n",
       " ('virgin', 0.5070083141326904)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecco_model.most_similar(positive=['she','her','hers','herself'], negative=['he','him','his','himself'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this differ from our novels model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lovely', 0.5201287269592285),\n",
       " ('sweet', 0.49211084842681885),\n",
       " ('beautiful', 0.4811100661754608),\n",
       " ('miss', 0.4612177014350891),\n",
       " ('maiden', 0.4426001310348511),\n",
       " ('beauty', 0.4329194128513336),\n",
       " ('soft', 0.42993593215942383),\n",
       " ('girlish', 0.42027080059051514),\n",
       " ('charming', 0.419153094291687),\n",
       " ('anne', 0.41564005613327026)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['she','her','hers','herself'], negative=['he','him','his','himself'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ECCO model and our model are not that different. 'Softness' and 'soft' are on the Ecco model, but only 'soft is on our model. 'Lovely' and 'maiden' are on both. These words are similar semantically. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "# Homework\n",
    "\n",
    "Heuser's blog post explores an analogy in eighteenth-century thought that Riches are to Virtue what Learning is to Genius. How true is this in the ECCO-trained Word2Vec model? Is it true in the one we trained?\n",
    "\n",
    "How might we compare word2vec models more generally?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('piety', 0.7372761368751526),\n",
       " ('morality', 0.7266900539398193),\n",
       " ('science', 0.6974709630012512),\n",
       " ('prudence', 0.6855395436286926),\n",
       " ('philosophy', 0.683079183101654),\n",
       " ('wisdom', 0.6511392593383789),\n",
       " ('genius', 0.6505820155143738),\n",
       " ('humanity', 0.640283465385437),\n",
       " ('modesty', 0.6369403004646301),\n",
       " ('morals', 0.6340599060058594)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecco_model.most_similar(positive=['learning', 'virtue'], negative=['riches'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('religion', 0.6676865816116333),\n",
       " ('philosophy', 0.6445833444595337),\n",
       " ('principle', 0.633765697479248),\n",
       " ('science', 0.6102355122566223),\n",
       " ('teaching', 0.5939815044403076),\n",
       " ('wisdom', 0.5931830406188965),\n",
       " ('moral', 0.5822182893753052),\n",
       " ('honesty', 0.5808697938919067),\n",
       " ('poetry', 0.5704977512359619),\n",
       " ('excellence', 0.5680336952209473)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['learning', 'virtue'], negative=['riches'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is pretty true that 'Riches are to Virtue what Learning is to Genius' in the ECCO model, but it is not perfectly true that 'Riches are to Virtue what Learning is to Genius' in our model. We get 'Riches are to Virtue what Learning is to Wisdom,' and that's pretty close... but not perfect. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Alternative features for a classification model\n",
    "\n",
    "This is really cool but what implications does this have for our model of language? Well, word embeddings are simply more precise features of what we've been trying to get at already. That means we can use them in the machine learning models we've been building.\n",
    "\n",
    "Recall our DTM bag of words classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to /srv/app/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87250000000000005"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "reviews = [movie_reviews.raw(fileid) for fileid in movie_reviews.fileids()]\n",
    "judgements = [movie_reviews.categories(fileid)[0] for fileid in movie_reviews.fileids()]\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "X, y = shuffle(reviews, judgements, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)\n",
    "\n",
    "# get tfidf values\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(X)\n",
    "X_train_transformed = tfidf.transform(X_train)\n",
    "X_test_transformed = tfidf.transform(X_test)\n",
    "\n",
    "# build and test logit\n",
    "logit_class = LogisticRegression(penalty='l2', C=1000)\n",
    "logit_model = logit_class.fit(X_train_transformed, y_train)\n",
    "logit_model.score(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1600x39659 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 536995 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "So how can we use word embeddings as features? Believe it or not, one of the most effective ways is to simply average each dimension of our embedding across all the words for a given document. Recall our w2v model for novels was trained for 100 dimensions. Creating the features for a specific document would entail first extracting the 100 dimensions for each word, then average each dimension across all words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.37198108,  0.31004509,  0.27318656,  0.12429547, -0.31546926,\n",
       "       -0.42679334, -0.27900964, -0.47647041,  0.58899206, -0.41408101,\n",
       "       -0.50325602, -0.35237777, -0.10169442,  0.06659365, -0.01462756,\n",
       "        0.05575463, -0.2640667 ,  0.34704971,  0.65704137, -0.95763993,\n",
       "        0.09823923, -0.01153611,  0.0378325 , -0.09742489, -0.01887065,\n",
       "       -0.53946471, -0.09942861,  0.12192144,  0.40095353, -0.02425315,\n",
       "       -0.36271036, -0.03407453, -0.03632429,  0.06841011,  0.29264039,\n",
       "        0.0257862 ,  0.63750136, -0.61148876, -0.24633352,  0.1958266 ,\n",
       "        0.10741864,  0.51742268, -0.05989947, -0.14527228,  0.03421893,\n",
       "        0.02046927, -0.47921425,  0.57887381, -0.18415298, -0.0115481 ,\n",
       "        0.57715958, -0.36509961,  0.12929302,  0.36910388,  0.21628399,\n",
       "       -0.065014  , -0.41967678,  0.2106555 ,  0.04700262,  0.11574005,\n",
       "       -0.31829113,  0.00777711,  0.54600132, -0.43242452, -0.33328974,\n",
       "        0.08188507, -0.10149925, -0.2297028 , -0.50486499, -0.50481755,\n",
       "       -0.06335108, -0.10722447,  0.03893548, -0.64343101, -0.1439888 ,\n",
       "       -0.25506705, -0.48205936, -0.25478041, -0.6242801 ,  0.46101928,\n",
       "        0.07474375,  0.36916885, -0.18073118,  0.74554807,  0.20632558,\n",
       "        0.05207742, -0.05409588,  0.00603498, -0.01093759,  0.34333971,\n",
       "        0.339867  ,  0.54348373,  0.8275916 , -0.38380033,  0.05678636,\n",
       "        0.03666146,  0.09853236, -0.61831719, -0.18148261,  0.0619252 ], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([model[w] for w in fast_tokenize(X[0]) if w in model], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a set `X` array with 100 features. We can write a function to do this for us for any given string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_featurize(document, model):\n",
    "    return np.mean([model[w] for w in fast_tokenize(document) if w in model], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then featurize all of our documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v = [w2v_featurize(d, model) for d in X_train]\n",
    "X_test_w2v = [w2v_featurize(d, model) for d in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fit and score the machine learning modle just as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77749999999999997"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_class = LogisticRegression(random_state=0, penalty='l2', C=1000)\n",
    "logit_model = logit_class.fit(X_train_w2v, y_train)\n",
    "logit_model.score(X_test_w2v, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about Heuser's model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ecco_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-89f2753990bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_w2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw2v_featurize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mecco_model\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test_w2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw2v_featurize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mecco_model\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogit_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlogit_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_w2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlogit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_w2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-89f2753990bf>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_w2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw2v_featurize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mecco_model\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test_w2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw2v_featurize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mecco_model\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogit_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlogit_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_w2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlogit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_w2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ecco_model' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_w2v = [w2v_featurize(d, ecco_model) for d in X_train]\n",
    "X_test_w2v = [w2v_featurize(d, ecco_model) for d in X_test]\n",
    "logit_class = LogisticRegression(random_state=0, penalty='l2', C=1000)\n",
    "logit_model = logit_class.fit(X_train_w2v, y_train)\n",
    "logit_model.score(X_test_w2v, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! But wait, what if we wanted to know *why* the model was making decisions. If we ask for the most postive coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([51,  4, 69, 92, 35, 44, 96, 45, 12, 83])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(logit_model.coef_[0])[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the negative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([97, 60, 38, 31, 61, 41, 22, 67,  7, 46])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(logit_model.coef_[0])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the *indices* for the important features. ***But what are these features now?***\n",
    "\n",
    "---\n",
    "\n",
    "Note that using our novels w2v model was not as accurate as a BoW tfidf method. That should be expected given movie review language is likely ***VERY*** different from our novel corpus. And our novel corpus likely didn't even have entries for a lot of the words used in our movie reviews corpus.\n",
    "\n",
    "For modern English, most people look for Stanford's [GloVe](https://nlp.stanford.edu/projects/glove/) model. This was trained on 6 billion tokens from Wikipedia and Gigaword! Quite a step up from 150 novels. Even the smallest model is a bit large to be working with on our cloud server, but using this model and the code below, you can see it's power:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> os.system('python -m gensim.scripts.glove2word2vec -i glove.6B.100d.txt -o glove.6B.100d.w2v.txt')\n",
    ">>> glove = gensim.models.KeyedVectors.load_word2vec_format('glove.6B.100d.w2v.txt')\n",
    "\n",
    ">>> X_train_glove = [w2v_featurize(d, glove) for d in X_train]\n",
    ">>> X_test_glove = [w2v_featurize(d, glove) for d in X_test]\n",
    "\n",
    ">>> logit_class = LogisticRegression(random_state=0, penalty='l2', C=1000)\n",
    ">>> logit_model = logit_class.fit(X_train_glove, y_train)\n",
    ">>> logit_model.score(X_test_glove, y_test)\n",
    "\n",
    ".8125\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is not as accurate as our BoW *tfidf* method, there have been several applications and transformations of word embeddings that have proven to be more accurate than a BoW *tfidf* on general modern text corpora. And keep in mind, one of the most interesting parts of this is that it only uses 100 dimensions, i.e., we can get ~81% accuracy by reducing a movie review to only 100 different features (our BoW model had over 39000!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1600x39659 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 536995 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
